{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Input Sentence : < he took the bus back >\n",
      "Expected Translation by Google : <Er hat den Bus zurÃ¼ck gebracht\n",
      "word 1 : < 1.00  ,  > 0.90  ,  ist 0.79  ,  \n",
      "word 2 : er 0.98  ,  > 0.87  ,  < 0.80  ,  \n",
      "word 3 : ist 0.81  ,  mir 0.54  ,  das 0.53  ,  \n",
      "word 4 : die 0.87  ,  > 0.76  ,  < 0.75  ,  \n",
      "word 5 : das 0.53  ,  ist 0.51  ,  sind 0.50  ,  \n",
      "word 6 : < 0.70  ,  das 0.61  ,  ist 0.54  ,  \n",
      "word 7 : > 1.00  ,  < 0.89  ,  ist 0.81  ,  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from mtranslate import translate\n",
    "import gensim\n",
    "\n",
    "with open('modelParameters.pickle', 'rb') as handle:\n",
    "    modelParametersDict = pickle.load(handle)\n",
    "\n",
    "Wxh = modelParametersDict['Wxh']\n",
    "Whh = modelParametersDict['Whh']\n",
    "Why = modelParametersDict['Why']\n",
    "bh = modelParametersDict['bh']\n",
    "by = modelParametersDict['by']\n",
    "hprev = modelParametersDict['hprev']\n",
    "char_en_to_vec = modelParametersDict['char_en_to_vec']\n",
    "vocab_size = 100\n",
    "modelDe = gensim.models.Word2Vec.load('german_word2vec_new')\n",
    "\n",
    "\n",
    "test_sentence = ['<', 'he', 'took', 'the', 'bus', 'back', '>']\n",
    "test_sentence_vec = [char_en_to_vec[ch] for ch in test_sentence]\n",
    "test_sentence_de= translate(' '.join(test_sentence),'de', 'en').split()\n",
    "\n",
    "\n",
    "\n",
    "def sample(h, n):\n",
    "  n = len(test_sentence_vec)\n",
    "  translated_vecs = []\n",
    "  for t in range(n):\n",
    "    #x = np.zeros((vocab_size, 1))\n",
    "    #x[char_to_ix[test_sentence[t]]] = 1\n",
    "    x = np.reshape(np.array(test_sentence_vec[t]), (vocab_size,1) )\n",
    "        \n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by   \n",
    "    translated_vecs.append(y)\n",
    "  return translated_vecs\n",
    "\n",
    "\n",
    "slen = len(test_sentence_vec)\n",
    "sample_vecs = sample(hprev, slen)\n",
    "\n",
    "print('---------------')\n",
    "print('Input Sentence : '+' '.join(test_sentence))\n",
    "print('Expected Translation by Google : '+' '.join(test_sentence_de))\n",
    "\n",
    "i = 0\n",
    "for v in sample_vecs:\n",
    "    top_n = modelDe.similar_by_vector(v.flatten(), topn=3, restrict_vocab=None)\n",
    "    print(\"word \"+str(i+1)+\" : \",end='')\n",
    "    for j in range(3):\n",
    "        print(top_n[j][0],\"%.2f\" %top_n[j][1] ,\" , \" ,end=' ')\n",
    "    i=i+1\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
